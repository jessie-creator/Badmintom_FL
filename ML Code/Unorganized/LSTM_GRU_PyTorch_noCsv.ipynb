{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p1wRKQ0xOFNN","executionInfo":{"status":"ok","timestamp":1701517803271,"user_tz":-480,"elapsed":22925,"user":{"displayName":"陳采妍","userId":"11888037513761062326"}},"outputId":"9a67cf2b-07fb-4e71-c0be-f65545a891bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# 球種選擇"],"metadata":{"id":"PwXexXApOgdW"}},{"cell_type":"code","source":["hittype = 0 # 高遠球:0, 挑球:1\n","\n","if hittype == 0:\n","  timeLenth = 60\n","  hittype_name = \"high\"\n","\n","elif hittype == 1:\n","  timeLenth = 50\n","  hittype_name = \"short\"\n","\n","else:\n","  print(\"error hittype\")\n"],"metadata":{"id":"2RNiN-mbOgE-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# cut function"],"metadata":{"id":"lV4aIXBKNjik"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"L99bNbNUMF4j"},"outputs":[],"source":["import os\n","import numpy as np\n","import csv\n","\n","def slope(input_data):\n","    slope_col = np.zeros(len(input_data),dtype=float)\n","    for i in range(len(input_data) - 1):\n","        for j in range(1,4):\n","            temp = input_data[i+1][j] - input_data[i][j]\n","            slope_col[i] += temp**2\n","        slope_col[i] = slope_col[i]**0.5\n","    return slope_col\n","\n","def ma(slope_col, n):\n","    slope_ma = np.zeros(len(slope_col),dtype=float)\n","    for i in range(n,len(slope_col)-n):\n","        for j in range(-n,n+1):\n","            slope_ma[i] += slope_col[i+j]\n","        slope_ma[i] /= float(2*n+1)\n","    return slope_ma\n","\n","def data_cut(input_data, save_data, hit_type):\n","    slope_col = slope(input_data)\n","    slope_avg = np.average(slope_col)\n","    # n = 4\n","    if hit_type == \"high\":\n","        n = 6\n","    elif hit_type == \"short\":\n","        n = 5\n","    slope_ma = ma(slope_col, n)\n","\n","    for i in range(60,len(slope_col)-50):\n","\n","        if ( slope_ma[i] > slope_avg ) and ( slope_col[i]==max(slope_col[i-50:i+50]) ) : # 找到可能峰值\n","            start = 0  # 向前&向後找起點\n","            end = 0\n","            while i+start > (50+n) :\n","                start -= 1\n","                if slope_ma[i+start] <= slope_avg:\n","                    break\n","            while i+end < (len(slope_col)-50-n) :\n","                end += 1\n","                if slope_ma[i+end] <= slope_avg:\n","                    break\n","\n","            if  hit_type == \"high\" and end-start > 40 and slope_ma[i] > 15: # 長遠球\n","                save_data.append(input_data[i-45:i+15, [1,2,3,5,6,7]])\n","\n","            elif hit_type == \"short\" and end-start > 20 and slope_ma[i] > 15: # 挑球\n","                save_data.append(input_data[i-35:i+15, [1,2,3,5,6,7]])\n","\n","# Removes null bytes from the input file and returns a sanitized version of the file.\n","def sanitize_file(input_file_path):\n","    sanitized_content = \"\"\n","    with open(input_file_path, 'r', encoding='utf-8', errors='replace') as f:\n","        content = f.read()\n","        sanitized_content = content.replace('\\x00', '')\n","\n","    return sanitized_content"]},{"cell_type":"code","source":["# 指定資料集所在的路徑\n","data_path =  \"/content/drive/MyDrive/資科羽球專題/data(.txt)\"\n","\n","# 取得該路徑下所有的檔案名稱\n","all_files = os.listdir(data_path)\n","\n","# 過濾出所有的 .txt 檔案\n","txt_files = [file_name for file_name in all_files if file_name.endswith('.txt') and hittype_name in file_name and len(file_name)>=30]\n","\n","labels = np.empty((0, 5), dtype=int)\n","data = np.empty((0, timeLenth, 6), dtype=float)\n","\n","for t, input_filename in enumerate(txt_files):\n","\n","    print(input_filename)\n","\n","    input_file_path = os.path.join(data_path, input_filename)\n","\n","    # Sanitize the file by removing null bytes\n","    sanitized_content = sanitize_file(input_file_path)\n","\n","    lines = sanitized_content.split('\\n')\n","\n","    # Starting from the last line, move upwards until a complete line (with 7 commas) is found\n","    while lines and lines[-1].count(\",\") != 7:\n","        lines = lines[:-1]\n","\n","    # Load the (potentially modified) data into a numpy array\n","    input_data = np.loadtxt(lines, delimiter=\",\", dtype=float)\n","\n","    save_data = []\n","\n","    data_cut(input_data, save_data, hittype_name)\n","\n","    save_data = np.array(save_data).astype(float)\n","\n","    data = np.concatenate((data, save_data), axis=0)\n","\n","    label_values = np.array([int(ch) for ch in input_filename[6:11]])  # 轉換為整數陣列\n","\n","    label_values = label_values[np.newaxis, :]  # 增加一個維度以使其成為二維陣列\n","\n","    for i in range(len(save_data)):\n","        labels = np.vstack((labels, label_values))\n","\n","print(data.shape)\n","print(labels.shape)"],"metadata":{"id":"_i1OZH5vMVfl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"39601c45-5220-455c-fcab-80b4585f9bc7","executionInfo":{"status":"ok","timestamp":1701517823420,"user_tz":-480,"elapsed":20155,"user":{"displayName":"陳采妍","userId":"11888037513761062326"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["h01_n_23342_110358030_high3.txt\n","h02_n_11122_101108044_high.txt\n","h03_y_55434_109703024_high.txt\n","h05_y_11111_110703043_high.txt\n","h06_y_33222_110302059_high.txt\n","h07_y_23221_109703056_high.txt\n","h08_y_22111_109703034_high.txt\n","h10_y_24244_109703003_high.txt\n","h11_n_22122_109540020_high.txt\n","h12_y_45543_109507014_high.txt\n","h13_y_11111_109305061_high.txt\n","h14_y_22121_109206049_high.txt\n","h15_y_33321_109101023_high.txt\n","h16_y_22111_109703018_high.txt\n","h09_y_23122_109703019_high.txt\n","(406, 60, 6)\n","(406, 5)\n"]}]},{"cell_type":"code","source":["# 指定資料集所在的路徑\n","data_path =  \"/content/drive/MyDrive/資科羽球專題/data(.txt)/1026\"\n","\n","# 取得該路徑下所有的檔案名稱\n","all_files = os.listdir(data_path)\n","\n","# 過濾出所有的 .txt 檔案\n","txt_files = [file_name for file_name in all_files if file_name.endswith('.txt') and hittype_name in file_name and len(file_name)>=30]\n","\n","for t, input_filename in enumerate(txt_files):\n","\n","    print(input_filename)\n","\n","    input_file_path = os.path.join(data_path, input_filename)\n","\n","    # Sanitize the file by removing null bytes\n","    sanitized_content = sanitize_file(input_file_path)\n","\n","    lines = sanitized_content.split('\\n')\n","\n","    # Starting from the last line, move upwards until a complete line (with 7 commas) is found\n","    while lines and lines[-1].count(\",\") != 7:\n","        lines = lines[:-1]\n","\n","    # Load the (potentially modified) data into a numpy array\n","    input_data = np.loadtxt(lines, delimiter=\",\", dtype=float)\n","\n","    save_data = []\n","\n","    data_cut(input_data, save_data, hittype_name)\n","\n","    save_data = np.array(save_data).astype(float)\n","\n","    data = np.concatenate((data, save_data), axis=0)\n","\n","    label_values = np.array([int(ch) for ch in input_filename[6:11]])  # 轉換為整數陣列\n","\n","    label_values = label_values[np.newaxis, :]  # 增加一個維度以使其成為二維陣列\n","\n","    for i in range(len(save_data)):\n","        labels = np.vstack((labels, label_values))\n","\n","# 指定資料集所在的路徑\n","data_path =  \"/content/drive/MyDrive/資科羽球專題/data(.txt)/1031\"\n","\n","# 取得該路徑下所有的檔案名稱\n","all_files = os.listdir(data_path)\n","\n","# 過濾出所有的 .txt 檔案\n","txt_files = [file_name for file_name in all_files if file_name.endswith('.txt') and hittype_name in file_name and len(file_name)>=30]\n","\n","for t, input_filename in enumerate(txt_files):\n","\n","    print(input_filename)\n","\n","    input_file_path = os.path.join(data_path, input_filename)\n","\n","    # Sanitize the file by removing null bytes\n","    sanitized_content = sanitize_file(input_file_path)\n","\n","    lines = sanitized_content.split('\\n')\n","\n","    # Starting from the last line, move upwards until a complete line (with 7 commas) is found\n","    while lines and lines[-1].count(\",\") != 7:\n","        lines = lines[:-1]\n","\n","    # Load the (potentially modified) data into a numpy array\n","    input_data = np.loadtxt(lines, delimiter=\",\", dtype=float)\n","\n","    save_data = []\n","\n","    data_cut(input_data, save_data, hittype_name)\n","\n","    save_data = np.array(save_data).astype(float)\n","\n","    data = np.concatenate((data, save_data), axis=0)\n","\n","    label_values = np.array([int(ch) for ch in input_filename[6:11]])  # 轉換為整數陣列\n","\n","    label_values = label_values[np.newaxis, :]  # 增加一個維度以使其成為二維陣列\n","\n","    for i in range(len(save_data)):\n","        labels = np.vstack((labels, label_values))\n","\n","print(data.shape)\n","print(labels.shape)"],"metadata":{"id":"JBeQJH9r8Eme","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701517849489,"user_tz":-480,"elapsed":26083,"user":{"displayName":"陳采妍","userId":"11888037513761062326"}},"outputId":"e582f216-5e6d-4389-e6d0-3f0629654a7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["h08_y_23233_102611108_high.txt\n","h07_y_12112_102611107_high.txt\n","h09_y_34432_102611109_high.txt\n","h10_y_12111_102611110_high.txt\n","h11_y_12122_102611111_high.txt\n","h12_y_22111_102611112_high.txt\n","h13_y_23121_102611113_high.txt\n","h01_y_55555_102611101_high.txt\n","h02_y_45554_102611102_high.txt\n","h03_y_55555_102611103_high.txt\n","h04_y_55555_102611104_high.txt\n","h05_y_55555_102611105_high.txt\n","h06_y_55444_102611106_high.txt\n","h11_y_55555_103100011_high.txt\n","h09_y_55555_103100009_high.txt\n","h08_y_55554_103100008_high.txt\n","h07_y_55555_103100007_high.txt\n","h06_y_55545_103100006_high.txt\n","h05_y_55555_103100005_high.txt\n","h10_y_55555_103100010_high.txt\n","h01_y_55555_103100001_high.txt\n","h02_y_44444_103100002_high.txt\n","h03_y_22233_103100003_high.txt\n","h04_y_55454_103100004_high.txt\n","(848, 60, 6)\n","(848, 5)\n"]}]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"U3opLLdwbSBv"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","#定義訓練集和測試集的比例，例如訓練集佔 80%，測試集佔 20%\n","train_ratio = 0.8\n","test_ratio = 0.2\n","x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test_ratio, random_state=24)\n","\n","print(x_train.shape)\n","print(x_test.shape)"],"metadata":{"id":"rN2G9iEtRFUC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701517850591,"user_tz":-480,"elapsed":1121,"user":{"displayName":"陳采妍","userId":"11888037513761062326"}},"outputId":"cb546a03-54b5-4fba-bed3-67e3cb928190"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(678, 60, 6)\n","(170, 60, 6)\n"]}]},{"cell_type":"code","source":["x_train = x_train.reshape(x_train.shape)\n","x_test = x_test.reshape(x_test.shape)"],"metadata":{"id":"iTuYe_95aek5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# 自定義輸出函數\n","def custom_output(x):\n","    return x\n","\n","# 自定義損失函數\n","def custom_loss(y_true, y_pred):\n","    loss = torch.mean((y_true - y_pred) ** 2)\n","    # loss = torch.mean(torch.square(y_true - y_pred))\n","    return loss\n","\n","# 自定義準確性函數\n","def custom_accuracy(y_true, y_pred):\n","    return torch.mean((torch.abs(y_true - y_pred) < 0.5).float(), dtype=torch.float32)\n","\n","# LSTM\n","class CustomLSTMModel(nn.Module):\n","    def __init__(self, input_size, units, output_dim, num_layers, dropout_rate):\n","        super(CustomLSTMModel, self).__init__()\n","        self.lstm_layers = nn.ModuleList(\n","            [nn.LSTM(input_size if i == 0 else units, units, batch_first=True) for i in range(num_layers)]\n","        )\n","        self.dropout = nn.Dropout(p=dropout_rate)\n","        self.dense = nn.Linear(units, output_dim)\n","\n","    def forward(self, x):\n","        for lstm_layer in self.lstm_layers:\n","            x, _ = lstm_layer(x)\n","            x = self.dropout(x)\n","        x = x[:, -1, :]  # 只取序列的最後一個時間步\n","        x = self.dense(x)\n","        return custom_output(x)\n","\n","# GRU\n","class CustomGRUModel(nn.Module):\n","    def __init__(self, input_size, units, output_dim, num_layers, dropout_rate):\n","        super(CustomGRUModel, self).__init__()\n","        self.gru_layers = nn.ModuleList(\n","            [nn.GRU(input_size if i == 0 else units, units, batch_first=True) for i in range(num_layers)]\n","        )\n","        self.dropout = nn.Dropout(p=dropout_rate)\n","        self.dense = nn.Linear(units, output_dim)\n","\n","    def forward(self, x):\n","        for gru_layer in self.gru_layers:\n","            x, _ = gru_layer(x)\n","            x = self.dropout(x)\n","        x = x[:, -1, :]  # 只取序列的最後一個時間步\n","        x = self.dense(x)\n","        return custom_output(x)"],"metadata":{"id":"4GHnf1tMaTfz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MyDataset(Dataset):\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        x = self.data[index]\n","        y = self.labels[index]\n","        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)"],"metadata":{"id":"MWmiH4jxgKl9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Early Stopping 早停法\n","class EarlyStopping:\n","    def __init__(self, patience=5, min_delta=0):\n","        \"\"\"\n","        Early stopping utility.\n","\n","        :param patience: 數量的 epochs，在這些 epochs 中如果損失沒有改善，則提前停止訓練。\n","        :param min_delta: 被認為是改善的最小變化量。\n","        \"\"\"\n","        self.patience = patience\n","        self.min_delta = min_delta\n","        self.counter = 0\n","        self.best_loss = None\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss):\n","        if self.best_loss is None:\n","            self.best_loss = val_loss\n","        elif self.best_loss - val_loss > self.min_delta:\n","            self.best_loss = val_loss\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                self.early_stop = True"],"metadata":{"id":"quLmsZuxZMRQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 超參數\n","\n","learning_rate = 0.01\n","batch_size = 20\n","numEpoch = 40\n","output_dim = 5\n","num_layers = 2\n","dropout_rate = 0.1\n","input_size = 6"],"metadata":{"id":"Fv_Awi6rA3vk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### LSTM Result"],"metadata":{"id":"PzL6XTOPbhjT"}},{"cell_type":"code","source":["# 使用MyDataset類\n","train_dataset = MyDataset(x_train, y_train)\n","test_dataset = MyDataset(x_test, y_test)\n","\n","# 使用DataLoader來創建數據集對象\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Instantiate the custom model\n","model = CustomLSTMModel(input_size=input_size, units=64, output_dim=output_dim, num_layers=num_layers, dropout_rate=dropout_rate)\n","\n","# 定義損失函數和優化器\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","loss_fn = custom_loss\n","\n","# 訓練循環\n","early_stopping = EarlyStopping(patience=10, min_delta=0.01)\n","\n","for epoch in range(numEpoch):\n","    model.train()\n","    for x_batch, y_batch in train_dataloader:\n","        optimizer.zero_grad()\n","        y_pred = model(x_batch)\n","        loss = loss_fn(y_batch, y_pred)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 評估\n","    model.eval()\n","    with torch.no_grad():\n","        total_loss = 0\n","        total_accuracy = 0\n","        for x_batch, y_batch in test_dataloader:\n","            y_pred = model(x_batch)\n","            total_loss += loss_fn(y_batch, y_pred).item()\n","            total_accuracy += custom_accuracy(y_batch, y_pred).item()\n","    avg_loss = total_loss / len(test_dataloader)\n","    avg_accuracy = total_accuracy / len(test_dataloader)\n","    print(f'Epoch {epoch+1}, Loss: {avg_loss}, Accuracy: {avg_accuracy}')\n","\n","    # Early Stopping 檢查\n","    early_stopping(avg_loss)\n","    if early_stopping.early_stop:\n","        print(\"Early stopping triggered\")\n","        break"],"metadata":{"id":"aCc9VqbkqeVy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1700378876080,"user_tz":-480,"elapsed":20960,"user":{"displayName":"陳采妍","userId":"11888037513761062326"}},"outputId":"27cccb22-2388-4688-e102-e1d654ecc661"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 1.74037770430247, Accuracy: 0.2622222188446257\n","Epoch 2, Loss: 1.4938281377156575, Accuracy: 0.2466666665342119\n","Epoch 3, Loss: 1.4506947331958346, Accuracy: 0.2822222196393543\n","Epoch 4, Loss: 1.4208719664149814, Accuracy: 0.3099999974171321\n","Epoch 5, Loss: 1.1966414716508653, Accuracy: 0.4444444411330753\n","Epoch 6, Loss: 1.0938887496789296, Accuracy: 0.465555555290646\n","Epoch 7, Loss: 0.90241054031584, Accuracy: 0.4666666587193807\n","Epoch 8, Loss: 0.7573856628603406, Accuracy: 0.4933333231343163\n","Epoch 9, Loss: 0.6362450685766008, Accuracy: 0.5122222205003103\n","Epoch 10, Loss: 0.7548021309905582, Accuracy: 0.5299999978807237\n","Epoch 11, Loss: 0.6490569611390432, Accuracy: 0.573333332935969\n","Epoch 12, Loss: 0.6856697681877348, Accuracy: 0.5444444384839799\n","Epoch 13, Loss: 0.6715064860052533, Accuracy: 0.5622222191757626\n","Epoch 14, Loss: 0.6966277029779222, Accuracy: 0.5677777760558658\n","Epoch 15, Loss: 0.7265311843819089, Accuracy: 0.5444444384839799\n","Epoch 16, Loss: 0.8304359846644931, Accuracy: 0.49333333637979293\n","Epoch 17, Loss: 0.8321045703358121, Accuracy: 0.5744444462988112\n","Epoch 18, Loss: 0.821687122186025, Accuracy: 0.5499999986754524\n","Epoch 19, Loss: 0.6096611519654592, Accuracy: 0.633333338631524\n","Epoch 20, Loss: 0.695266154077318, Accuracy: 0.6366666687859429\n","Epoch 21, Loss: 0.6089113487137688, Accuracy: 0.6744444436497159\n","Epoch 22, Loss: 0.5398802326785194, Accuracy: 0.6933333211474948\n","Epoch 23, Loss: 0.5418317152394189, Accuracy: 0.6955555611186557\n","Epoch 24, Loss: 0.45752527316411334, Accuracy: 0.7088888883590698\n","Epoch 25, Loss: 0.5064952224493027, Accuracy: 0.6922222243414985\n","Epoch 26, Loss: 0.560707602236006, Accuracy: 0.6588888896836175\n","Epoch 27, Loss: 0.6132106681664785, Accuracy: 0.6355555521117316\n","Epoch 28, Loss: 0.4805000490612454, Accuracy: 0.7299999992052714\n","Epoch 29, Loss: 0.548605246676339, Accuracy: 0.6888888941870795\n","Epoch 30, Loss: 0.7231149342324998, Accuracy: 0.6677777767181396\n","Epoch 31, Loss: 0.7505792876084646, Accuracy: 0.6788888838556077\n","Epoch 32, Loss: 0.7670146657360924, Accuracy: 0.6722222301695082\n","Epoch 33, Loss: 0.6827724476655325, Accuracy: 0.7188888920678033\n","Epoch 34, Loss: 0.6638753828075197, Accuracy: 0.7155555486679077\n","Early stopping triggered\n"]}]},{"cell_type":"markdown","source":["### GRU Result"],"metadata":{"id":"PBXlzkKdbloZ"}},{"cell_type":"code","source":["# 使用MyDataset類\n","train_dataset = MyDataset(x_train, y_train)\n","test_dataset = MyDataset(x_test, y_test)\n","\n","# 使用DataLoader來創建數據集對象\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Instantiate the custom model\n","model = CustomGRUModel(input_size=input_size, units=64, output_dim=output_dim, num_layers=num_layers, dropout_rate=dropout_rate)\n","\n","# 定義損失函數和優化器\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","loss_fn = custom_loss\n","\n","# 訓練循環\n","early_stopping = EarlyStopping(patience=10, min_delta=0.01)\n","\n","for epoch in range(numEpoch):\n","    model.train()\n","    for x_batch, y_batch in train_dataloader:\n","        optimizer.zero_grad()\n","        y_pred = model(x_batch)\n","        loss = loss_fn(y_batch, y_pred)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 評估\n","    model.eval()\n","    with torch.no_grad():\n","        total_loss = 0\n","        total_accuracy = 0\n","        for x_batch, y_batch in test_dataloader:\n","            y_pred = model(x_batch)\n","            total_loss += loss_fn(y_batch, y_pred).item()\n","            total_accuracy += custom_accuracy(y_batch, y_pred).item()\n","    avg_loss = total_loss / len(test_dataloader)\n","    avg_accuracy = total_accuracy / len(test_dataloader)\n","    print(f'Epoch {epoch+1}, Loss: {avg_loss}, Accuracy: {avg_accuracy}')\n","\n","    # Early Stopping 檢查\n","    early_stopping(avg_loss)\n","    if early_stopping.early_stop:\n","        print(\"Early stopping triggered\")\n","        break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tvtjnKr7fYNK","executionInfo":{"status":"ok","timestamp":1700378908619,"user_tz":-480,"elapsed":32546,"user":{"displayName":"陳采妍","userId":"11888037513761062326"}},"outputId":"71d4fa26-6aba-41de-c076-afaad2ab8ba8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 1.1648907661437988, Accuracy: 0.3122222257985009\n","Epoch 2, Loss: 0.8109479579660628, Accuracy: 0.4911111063427395\n","Epoch 3, Loss: 0.6279211706585355, Accuracy: 0.5377777748637729\n","Epoch 4, Loss: 0.6942077941364713, Accuracy: 0.5677777694331275\n","Epoch 5, Loss: 0.4506952183114158, Accuracy: 0.6766666637526618\n","Epoch 6, Loss: 0.49642591012848747, Accuracy: 0.6800000071525574\n","Epoch 7, Loss: 0.46355507771174115, Accuracy: 0.7311111092567444\n","Epoch 8, Loss: 0.3929712093538708, Accuracy: 0.694444457689921\n","Epoch 9, Loss: 0.24266531566778818, Accuracy: 0.7677777740690443\n","Epoch 10, Loss: 0.3751177423530155, Accuracy: 0.7855555613835653\n","Epoch 11, Loss: 0.3460340549548467, Accuracy: 0.8088888857099745\n","Epoch 12, Loss: 0.37087380554940963, Accuracy: 0.817777779367235\n","Epoch 13, Loss: 0.3505641304784351, Accuracy: 0.8499999973509047\n","Epoch 14, Loss: 0.3559948297010528, Accuracy: 0.8066666656070285\n","Epoch 15, Loss: 0.3218233154879676, Accuracy: 0.8100000023841858\n","Epoch 16, Loss: 0.2845708694722917, Accuracy: 0.8422222269905938\n","Epoch 17, Loss: 0.3224486716919475, Accuracy: 0.8411111169391208\n","Epoch 18, Loss: 0.23721970203850004, Accuracy: 0.8244444396760728\n","Epoch 19, Loss: 0.24608279516299567, Accuracy: 0.8622222277853224\n","Early stopping triggered\n"]}]}]}