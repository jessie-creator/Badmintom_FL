{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "切資料\n"
      ],
      "metadata": {
        "id": "5T1kl6tl87QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "def slope(input_data):\n",
        "    slope_col = np.zeros(len(input_data),dtype=float)\n",
        "    for i in range(len(input_data) - 1):\n",
        "        for j in range(1,4):\n",
        "            temp = input_data[i+1][j] - input_data[i][j]\n",
        "            slope_col[i] += temp**2\n",
        "        slope_col[i] = slope_col[i]**0.5\n",
        "    return slope_col\n",
        "\n",
        "def ma(slope_col, n):\n",
        "    slope_ma = np.zeros(len(slope_col),dtype=float)\n",
        "    for i in range(n,len(slope_col)-n):\n",
        "        for j in range(-n,n+1):\n",
        "            slope_ma[i] += slope_col[i+j]\n",
        "        slope_ma[i] /= float(2*n+1)\n",
        "    return slope_ma\n",
        "\n",
        "def data_cut(input_data, save_data, n, ball_type):\n",
        "    slope_col = slope(input_data)\n",
        "    slope_avg = np.average(slope_col)\n",
        "    slope_ma = ma(slope_col, n)\n",
        "\n",
        "    for i in range(60,len(slope_col)-50):\n",
        "\n",
        "        if ( slope_ma[i] > slope_avg ) and ( slope_col[i]==max(slope_col[i-50:i+50]) ) : # 找到可能峰值\n",
        "            start = 0  # 向前&向後找起點\n",
        "            end = 0\n",
        "            while i+start > (50+n) :\n",
        "                start -= 1\n",
        "                if slope_ma[i+start] <= slope_avg:\n",
        "                    break\n",
        "            while i+end < (len(slope_col)-50-n) :\n",
        "                end += 1\n",
        "                if slope_ma[i+end] <= slope_avg:\n",
        "                    break\n",
        "            if end-start > 50: # 依球種分類存入 save_data\n",
        "                if ball_type == \"high\": # 長遠球\n",
        "                    save_data.append(input_data[i-60:i+40, [1,2,3,5,6,7]])\n",
        "                elif ball_type == \"short\": # 挑球\n",
        "                    save_data.append(input_data[i-40:i+20, [1,2,3,5,6,7]])\n",
        "\n",
        "# Removes null bytes from the input file and returns a sanitized version of the file.\n",
        "def sanitize_file(input_file_path):\n",
        "    sanitized_content = \"\"\n",
        "    with open(input_file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        content = f.read()\n",
        "        sanitized_content = content.replace('\\x00', '')\n",
        "\n",
        "    # Overwrite the original file with sanitized content\n",
        "    with open(input_file_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(sanitized_content)\n",
        "\n",
        "\n",
        "# 指定資料集所在的路徑\n",
        "data_path = \"/content/\"\n",
        "\n",
        "# 取得該路徑下所有的檔案名稱\n",
        "all_files = os.listdir(data_path)\n",
        "\n",
        "# 過濾出所有的 .txt 檔案\n",
        "txt_files = [file_name for file_name in all_files if file_name.endswith('.txt')]\n",
        "\n",
        "for t, input_filename in enumerate(txt_files):\n",
        "\n",
        "    input_file_path = os.path.join(data_path, input_filename)\n",
        "\n",
        "    # Sanitize the file by removing null bytes\n",
        "    sanitize_file(input_file_path)\n",
        "\n",
        "    # Read the entire file into memory\n",
        "    with open(input_file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # Starting from the last line, move upwards until a complete line (with 7 commas) is found\n",
        "    while lines and lines[-1].count(\",\") != 7:\n",
        "        lines = lines[:-1]\n",
        "\n",
        "    # Load the (potentially modified) data into a numpy array\n",
        "    input_data = np.loadtxt(lines, delimiter=\",\", dtype=float)\n",
        "    # print(input_filename)\n",
        "    # print(input_data)\n",
        "\n",
        "    # input_data = np.loadtxt(input_file_path, delimiter=\",\", dtype=float) # 從文本文件中讀取數據，以\",\"為分隔符號\n",
        "\n",
        "    save_data = []\n",
        "    n = 3   # n:取移動平均用，看前後需要取幾個\n",
        "\n",
        "    #決定球種\n",
        "    if \"high\" in input_filename.lower():\n",
        "        ball_type = \"high\"\n",
        "    elif \"short\" in input_filename.lower():\n",
        "        ball_type = \"short\"\n",
        "    else:\n",
        "        print(\"error txt-file\")\n",
        "\n",
        "    data_cut(input_data, save_data, n+1, ball_type)\n",
        "\n",
        "    save_data = np.array(save_data).astype(float)\n",
        "\n",
        "    print(input_filename)\n",
        "    print(len(save_data))\n",
        "\n",
        "    output_filename = input_filename.split(\".\")[0] + \"_cut.csv\"\n",
        "\n",
        "    output_file_path = data_path + \"\\\\\" + output_filename\n",
        "\n",
        "    with open(output_file_path, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile, delimiter=',')\n",
        "        for data in save_data:\n",
        "            formatted_data = [','.join(str(val) for val in row) for row in data]\n",
        "            writer.writerow(formatted_data)"
      ],
      "metadata": {
        "id": "xlKHK5rP86Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data to Array"
      ],
      "metadata": {
        "id": "miMdT6MS9Auy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "#常數放置區\n",
        "hittype = 1       #長球:0, 短球:1\n",
        "both_cols = 6\n",
        "high_rows = 100\n",
        "short_rows = 60\n",
        "high_file_end = 'high_cut.csv'\n",
        "short_file_end = 'short_cut.csv'\n",
        "#常數放置區\n",
        "#-----csv_cutdata to train_test_data----------\n",
        "# 指定数据集所在的路径\n",
        "data_path = '.'\n",
        "\n",
        "# 取得该路径下所有的文件名\n",
        "all_files = os.listdir(data_path)\n",
        "\n",
        "#長球:high_cut.csv, 短球:short_cut.csv\n",
        "dynamic_content = \"error\"\n",
        "if(hittype == 0):\n",
        "  dynamic_content = high_file_end\n",
        "elif(hittype == 1):\n",
        "  dynamic_content = short_file_end\n",
        "#print(dynamic_content)\n",
        "\n",
        "# 過濾出指定的 .csv 檔案\n",
        "target_files = [file_name for file_name in all_files if file_name.endswith(dynamic_content)]\n",
        "print(target_files)\n",
        "# 讀取檔案至三維矩陣\n",
        "num_rows = 0\n",
        "if(hittype == 0):\n",
        "  num_rows = high_rows\n",
        "elif(hittype == 1):\n",
        "  num_rows = short_rows\n",
        "num_cols = both_cols\n",
        "\n",
        "data = np.empty((0, num_rows, num_cols), dtype=int)\n",
        "labels = np.empty((0, 5), dtype=int)\n",
        "for i,file_name in enumerate(target_files):\n",
        "  file_path = os.path.join(data_path, file_name)\n",
        "  with open(file_path, 'r', newline='') as f:\n",
        "        read = csv.reader(f, delimiter=',')\n",
        "        read_list = list(read)\n",
        "        #print(len(read_list))\n",
        "  #print(len(read_list))\n",
        "  for j in range(len(read_list)):\n",
        "    #print(len(read_list[0]))\n",
        "    for k in range(len(read_list[0])):\n",
        "      read_list[j][k] = list(map(float, read_list[j][k].split(',')))\n",
        "    # Add the new column to the labels array\n",
        "    new_row = np.array([file_name[7], file_name[8], file_name[9], file_name[10], file_name[11]], dtype=int)\n",
        "    new_row = new_row - 1\n",
        "    labels = np.vstack((labels, new_row))\n",
        "  data = np.concatenate((data, read_list))\n",
        "\n",
        "numLable = len(target_files)\n",
        "#data=data.reshape(len(labels),num_rows*num_cols)\n",
        "print(data.shape)\n",
        "print(labels.shape)\n",
        "print(len(target_files))\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_yBO3Tf9DOY",
        "outputId": "eeff47c9-e96a-46ac-f453-f2a867ad4fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\\\s16_n_22122_109206014_short_cut.csv', '\\\\s10_y_44444_109703003_short_cut.csv', '\\\\s03_y_33222_110358030_short_cut.csv', '\\\\s07_y_11221_110703008_short_cut.csv', '\\\\s11_n_22222_110308047_short_cut.csv', '\\\\s12_y_22121_109703018_short_cut.csv', '\\\\s09_y_33222_109703056_short_cut.csv', '\\\\s08_n_22232_110302059_short_cut.csv', '\\\\s01_y_13231_234234234_short_cut.csv', '\\\\s14_y_44443_109507014_short_cut.csv', '\\\\s04_y_11121_101108044_short_cut.csv', '\\\\s06_n_12121_111206016_short_cut.csv', '\\\\s05_y_44334_109703024_short_cut.csv', '\\\\s13_n_11111_109540020_short_cut.csv', '\\\\s15_y_11111_109305061_short_cut.csv', '\\\\s02_y_11111_123123123_short_cut.csv']\n",
            "(230, 60, 6)\n",
            "(230, 5)\n",
            "16\n",
            "[[1 1 0 1 1]\n",
            " [1 1 0 1 1]\n",
            " [1 1 0 1 1]\n",
            " ...\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]\n",
            " [0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#定義訓練集和測試集的比例，例如訓練集佔 80%，測試集佔 20%\n",
        "train_ratio = 0.8\n",
        "test_ratio = 0.2\n",
        "#labels = labels2\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test_ratio, random_state=24)"
      ],
      "metadata": {
        "id": "L1bSJ2qfIbkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "x_train = x_train.reshape(184, 60, 6)\n",
        "x_test = x_test.reshape(46, 60, 6)"
      ],
      "metadata": {
        "id": "dqkckknSIjPY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40797ff-543b-467f-8b02-bdc2b8b367c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(184, 60, 6)\n",
            "(46, 60, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install tflite_runtime"
      ],
      "metadata": {
        "id": "JoCzje-fQ9x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "42liPMOzInd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset:\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.labels[index]\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "y8wswnHhIuWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#常數放置區\n",
        "numEpoch = 30\n",
        "batch_size = 8\n",
        "\n",
        "if(hittype == 0):\n",
        "  Time_Step = 100\n",
        "elif(hittype == 1):\n",
        "  Time_Step = 60\n",
        "\n",
        "Input_Size = 6\n",
        "learning_rate = 0.01\n",
        "\n",
        "Hidden_Size = 16\n",
        "Num_Layers = 2\n",
        "# Output_Size由類別數決定，若分n類，則為n\n",
        "# 這裡 = len(target_files)是因為同一人的資料不會出現第2次\n",
        "# 未來 = 錯誤類別數\n",
        "Output_Size = 5\n",
        "\n",
        "number_of_samples = 3\n",
        "momentum = 0.9\n",
        "\n",
        "#定義訓練集和測試集的比例，例如訓練集佔 80%，測試集佔 20%\n",
        "train_ratio = 0.8\n",
        "test_ratio = 0.2"
      ],
      "metadata": {
        "id": "UUiagYoxIx82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dim = 5"
      ],
      "metadata": {
        "id": "SrCeuR_eIMFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test_ratio, random_state=42)\n",
        "#x_train, y_train, x_test, y_test = map(torch.tensor, (x_train, y_train, x_test, y_test))"
      ],
      "metadata": {
        "id": "iuo8cWJWI1SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_test.shape)\n",
        "print(y_train.shape, y_test.shape)\n",
        "X_train = x_train.reshape(184, 360)\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
        "X_test = x_test.reshape(46, 360)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy7axNUGK_aK",
        "outputId": "7447824b-738f-41e3-b4ce-555f8d72d3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(184, 60, 6) (46, 60, 6)\n",
            "(184, 5) (46, 5)\n",
            "(184, 1, 360) (46, 1, 360)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FEnhlKxLILO",
        "outputId": "acf48b34-5b32-4b5a-f58d-7a479380ee48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 2s 7ms/step - loss: 1.1926 - custom_accuracy: 0.4522\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7343 - custom_accuracy: 0.5359\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.5883 - custom_accuracy: 0.6000\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4930 - custom_accuracy: 0.6641\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4187 - custom_accuracy: 0.7130\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3574 - custom_accuracy: 0.7696\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3084 - custom_accuracy: 0.8054\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2670 - custom_accuracy: 0.8402\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2309 - custom_accuracy: 0.8707\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2031 - custom_accuracy: 0.8739\n",
            "2/2 [==============================] - 1s 10ms/step - loss: 0.3107 - custom_accuracy: 0.7739\n",
            "Loss: 0.31070902943611145, Custom Accuracy: 0.7739130258560181\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "\n",
        "# Define custom output function\n",
        "def custom_output(x):\n",
        "    # Implement your custom output logic here\n",
        "    return x\n",
        "\n",
        "# Define custom loss function\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_loss(y_true, y_pred):\n",
        "    y_true = tf.cast(y_true, dtype=tf.float32)  # Cast y_true to float32\n",
        "    loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    return loss\n",
        "\n",
        "# Define custom accuracy function\n",
        "threshold = 0.5\n",
        "def custom_accuracy(y_true, y_pred):\n",
        "    abs_diff = tf.abs(y_true - y_pred)\n",
        "    condition = tf.less_equal(abs_diff, threshold)\n",
        "    acc = tf.cast(condition, tf.float32)\n",
        "    return acc\n",
        "\n",
        "# Create a custom LSTM model\n",
        "class CustomLSTMModel(Model):\n",
        "    def __init__(self, units, output_dim):\n",
        "        super(CustomLSTMModel, self).__init__()\n",
        "        self.lstm = LSTM(units)\n",
        "        self.dense = Dense(output_dim, activation=custom_output)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # x = self.lstm(inputs)\n",
        "        # return self.dense(x)\n",
        "        lstm_output = self.lstm(inputs)\n",
        "        output = self.dense(lstm_output)\n",
        "        output = custom_output(output)\n",
        "        return output\n",
        "\n",
        "# Instantiate the custom model\n",
        "model = CustomLSTMModel(units=64, output_dim=output_dim)\n",
        "\n",
        "# Compile the model with custom loss and accuracy functions\n",
        "model.compile(optimizer='adam', loss=custom_loss, metrics=[custom_accuracy])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Loss: {loss}, Custom Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)\n",
        "custom_accuracies = custom_accuracy(y_test, y_pred)\n",
        "\n",
        "for i in range(5):\n",
        "    accuracy_i = custom_accuracies[:, i]\n",
        "    accuracy_i_value = tf.reduce_mean(accuracy_i).numpy()\n",
        "    print(f'Custom Accuracy Component {i + 1}: {accuracy_i_value}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GylZcYvi2f-_",
        "outputId": "c171bf13-da54-4a36-f90e-637a1d947c23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 12ms/step\n",
            "Custom Accuracy Component 1: 0.6521739363670349\n",
            "Custom Accuracy Component 2: 0.695652186870575\n",
            "Custom Accuracy Component 3: 0.8478260636329651\n",
            "Custom Accuracy Component 4: 0.782608687877655\n",
            "Custom Accuracy Component 5: 0.8913043737411499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "#常數放置區\n",
        "hittype = 1       #長球:0, 短球:1\n",
        "both_cols = 6\n",
        "high_rows = 100\n",
        "short_rows = 60\n",
        "high_file_end = 'high_cut.csv'\n",
        "short_file_end = 'short_cut.csv'\n",
        "#常數放置區\n",
        "#-----csv_cutdata to train_test_data----------\n",
        "# 指定数据集所在的路径\n",
        "data_path = '.'\n",
        "\n",
        "# 取得该路径下所有的文件名\n",
        "all_files = os.listdir(data_path)\n",
        "\n",
        "#長球:high_cut.csv, 短球:short_cut.csv\n",
        "dynamic_content = \"error\"\n",
        "if(hittype == 0):\n",
        "  dynamic_content = high_file_end\n",
        "elif(hittype == 1):\n",
        "  dynamic_content = short_file_end\n",
        "#print(dynamic_content)\n",
        "\n",
        "# 過濾出指定的 .csv 檔案\n",
        "target_files = '\\s04_y_11121_101108044_short_cut.csv'\n",
        "print(target_files)\n",
        "# 讀取檔案至三維矩陣\n",
        "num_rows = 0\n",
        "if(hittype == 0):\n",
        "  num_rows = high_rows\n",
        "elif(hittype == 1):\n",
        "  num_rows = short_rows\n",
        "num_cols = both_cols\n",
        "file_name = '\\s03_y_33222_110358030_short_cut.csv'\n",
        "the_scored_file = np.empty((0, num_rows, num_cols), dtype=int)\n",
        "the_scored = np.empty((0, 5), dtype=int)\n",
        "file_path = os.path.join(data_path, file_name)\n",
        "with open(file_path, 'r', newline='') as f:\n",
        "      read = csv.reader(f, delimiter=',')\n",
        "      read_list = list(read)\n",
        "      #print(len(read_list))\n",
        "#print(len(read_list))\n",
        "for j in range(len(read_list)):\n",
        "  #print(len(read_list[0]))\n",
        "  for k in range(len(read_list[0])):\n",
        "    read_list[j][k] = list(map(float, read_list[j][k].split(',')))\n",
        "  # Add the new column to the labels array\n",
        "  new_row = np.array([file_name[7], file_name[8], file_name[9], file_name[10], file_name[11]], dtype=int)\n",
        "  new_row = new_row - 1\n",
        "  the_scored = np.vstack((the_scored, new_row))\n",
        "the_scored_file = np.concatenate((the_scored_file, read_list))\n",
        "\n",
        "numLable = len(target_files)\n",
        "print(the_scored_file.shape)\n",
        "the_scored_file = the_scored_file.reshape(the_scored_file.shape[0], 360)\n",
        "the_scored_file = the_scored_file.reshape(the_scored_file.shape[0], 1, the_scored_file.shape[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zKv3tzm6L_K",
        "outputId": "3d6d0407-7a5a-437e-a149-ba849c245a54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\s04_y_11121_101108044_short_cut.csv\n",
            "(7, 60, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def custom_prediction(swings):\n",
        "    processed_swings = np.array(swings)\n",
        "    scores = model.predict(processed_swings)\n",
        "    #average_scores = np.mean(scores, axis=0)\n",
        "    average_scores = np.mean(np.round(scores), axis=0)\n",
        "    rounded_average_scores = np.round(average_scores)+1\n",
        "    return rounded_average_scores\n",
        "\n",
        "# Obtain the average scores for the actions\n",
        "average_scores = custom_prediction(the_scored_file)\n",
        "print(\"Average Scores (Rounded):\", average_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRzyi7p976AL",
        "outputId": "70bf81db-e9ba-48b4-b583-5a488e640bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "Average Scores (Rounded): [2. 3. 2. 2. 1.]\n"
          ]
        }
      ]
    }
  ]
}